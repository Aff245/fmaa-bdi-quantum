name: ðŸ¤– Quantum BDI Agent CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'full'
        type: choice
        options:
          - 'full'
          - 'quantum_only'
          - 'bdi_only'
          - 'integration'
          - 'benchmarks'
      quantum_backend:
        description: 'Quantum backend to use'
        required: false
        default: 'qasm_simulator'
        type: choice
        options:
          - 'qasm_simulator'
          - 'statevector_simulator'
          - 'aer_simulator'
          - 'pennylane_default'

env:
  PYTHON_VERSION: '3.11'
  QUANTUM_CACHE_VERSION: 'v1'

jobs:
  # Pre-check job to validate environment
  pre-check:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      should_run_quantum: ${{ steps.check.outputs.quantum }}
      should_run_bdi: ${{ steps.check.outputs.bdi }}
      python_matrix: ${{ steps.check.outputs.python_versions }}
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2
    
    - name: ðŸ” Check Changes and Set Outputs
      id: check
      run: |
        # Check which components have changes
        if git diff --name-only HEAD~1 | grep -E "(quantum/|requirements-quantum)" || [ "${{ github.event.inputs.test_type }}" = "quantum_only" ] || [ "${{ github.event.inputs.test_type }}" = "full" ]; then
          echo "quantum=true" >> $GITHUB_OUTPUT
        else
          echo "quantum=false" >> $GITHUB_OUTPUT
        fi
        
        if git diff --name-only HEAD~1 | grep -E "(agents/|requirements\.txt)" || [ "${{ github.event.inputs.test_type }}" = "bdi_only" ] || [ "${{ github.event.inputs.test_type }}" = "full" ]; then
          echo "bdi=true" >> $GITHUB_OUTPUT
        else
          echo "bdi=false" >> $GITHUB_OUTPUT
        fi
        
        # Set Python versions for matrix
        echo 'python_versions=["3.9", "3.10", "3.11"]' >> $GITHUB_OUTPUT

  # Quantum Computing Tests
  quantum-tests:
    needs: pre-check
    if: needs.pre-check.outputs.should_run_quantum == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        python-version: ${{ fromJson(needs.pre-check.outputs.python_matrix) }}
        quantum-backend: ['qasm_simulator', 'statevector_simulator', 'aer_simulator']
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
        cache-dependency-path: |
          requirements.txt
          requirements-quantum.txt
          requirements-dev.txt
    
    - name: ðŸ”§ Install System Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential gfortran libopenblas-dev
    
    - name: âš›ï¸ Install Quantum Dependencies
      run: |
        python -m pip install --upgrade pip wheel setuptools
        
        # Install core dependencies first
        pip install -r requirements.txt
        
        # Install quantum-specific dependencies with optimizations
        pip install -r requirements-quantum.txt
        
        # Install development dependencies
        pip install -r requirements-dev.txt
        
        # Verify installations
        python -c "import qiskit; print(f'Qiskit version: {qiskit.__version__}')"
        python -c "import pennylane; print(f'PennyLane version: {pennylane.__version__}')"
    
    - name: ðŸ§ª Run Quantum Engine Tests
      env:
        QUANTUM_BACKEND: ${{ matrix.quantum-backend }}
      run: |
        # Run quantum-specific tests
        pytest tests/quantum/ -v --tb=short --cov=quantum --cov-report=xml
        
        # Run quantum algorithm benchmarks
        python scripts/benchmark_performance.py --backend=${{ matrix.quantum-backend }}
    
    - name: âš›ï¸ Test Quantum-BDI Integration
      run: |
        # Test quantum optimization in BDI system
        python -m pytest tests/integration/test_quantum_bdi.py -v
        
        # Run quantum circuit validation
        python quantum/quantum_engine.py --test-mode --backend=${{ matrix.quantum-backend }}
    
    - name: ðŸ“Š Generate Quantum Performance Report
      if: always()
      run: |
        python scripts/generate_reports.py --type=quantum --backend=${{ matrix.quantum-backend }}
        
        # Archive performance data
        mkdir -p reports/quantum/${{ matrix.python-version }}
        cp data/output/*.json reports/quantum/${{ matrix.python-version }}/
    
    - name: ðŸ“¤ Upload Quantum Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: quantum-results-py${{ matrix.python-version }}-${{ matrix.quantum-backend }}
        path: |
          reports/
          data/output/
          coverage.xml
        retention-days: 30

  # BDI Agent Tests
  bdi-agent-tests:
    needs: pre-check
    if: needs.pre-check.outputs.should_run_bdi == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      matrix:
        python-version: ${{ fromJson(needs.pre-check.outputs.python_matrix) }}
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: ðŸ”§ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        
        # Install quantum dependencies for BDI integration
        pip install qiskit==0.45.2 pennylane==0.33.1
    
    - name: ðŸ§  Test Belief System
      run: |
        pytest tests/unit/test_belief.py -v --cov=agents.belief
    
    - name: ðŸŽ¯ Test Desire System with Quantum Optimization
      run: |
        # Test both classical and quantum-enhanced desire optimization
        pytest tests/unit/test_desire.py -v --cov=agents.desire
        
        # Test quantum goal optimization
        python agents/desire/quantum_desires.py --test
    
    - name: âš¡ Test Intention System
      run: |
        pytest tests/unit/test_intention.py -v --cov=agents.intention
    
    - name: ðŸ¤– Test Complete BDI Cycle
      run: |
        # Test full BDI agent operation
        pytest tests/test_bdi_core.py -v --cov=agents.bdi_core
        
        # Run integration test
        python agents/bdi_core.py --test-mode --cycles=3
    
    - name: ðŸ“Š BDI Performance Benchmarks
      run: |
        python scripts/benchmark_performance.py --type=bdi --cycles=10

  # Integration and End-to-End Tests
  integration-tests:
    needs: [quantum-tests, bdi-agent-tests]
    if: always() && (needs.quantum-tests.result == 'success' || needs.bdi-agent-tests.result == 'success')
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ”§ Install All Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-quantum.txt
        pip install -r requirements-dev.txt
    
    - name: ðŸ”„ Run Full Integration Tests
      run: |
        # Test quantum-BDI integration
        pytest tests/integration/ -v --tb=short --cov=. --cov-report=xml --cov-report=html
    
    - name: ðŸš€ End-to-End Workflow Test
      run: |
        # Run complete workflow simulation
        python examples/advanced/hybrid_workflows.py --test
        
        # Test performance under load
        python scripts/benchmark_performance.py --type=integration --duration=300
    
    - name: ðŸ“ˆ Generate Comprehensive Report
      if: always()
      run: |
        python scripts/generate_reports.py --type=comprehensive
        
        # Create test summary
        echo "## Test Summary" > test_summary.md
        echo "- Python Version: ${{ env.PYTHON_VERSION }}" >> test_summary.md
        echo "- Quantum Tests: ${{ needs.quantum-tests.result }}" >> test_summary.md
        echo "- BDI Tests: ${{ needs.bdi-agent-tests.result }}" >> test_summary.md
        echo "- Integration Tests: Complete" >> test_summary.md
    
    - name: ðŸ“¤ Upload Final Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: integration-test-results
        path: |
          reports/
          htmlcov/
          test_summary.md
          coverage.xml
        retention-days: 30

  # Performance Benchmarks (Optional)
  performance-benchmarks:
    if: github.event.inputs.test_type == 'benchmarks' || github.event.inputs.test_type == 'full'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ðŸ”§ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-quantum.txt
        pip install memory-profiler line-profiler py-spy
    
    - name: âš¡ Run Performance Benchmarks
      run: |
        # Quantum performance benchmarks
        python scripts/benchmark_performance.py --type=quantum --comprehensive
        
        # BDI system benchmarks
        python scripts/benchmark_performance.py --type=bdi --comprehensive
        
        # Memory usage profiling
        mprof run python agents/bdi_core.py --benchmark-mode
        mprof plot -o memory_usage.png
    
    - name: ðŸ“Š Generate Benchmark Report
      run: |
        python scripts/generate_reports.py --type=benchmarks
    
    - name: ðŸ“¤ Upload Benchmark Results
      uses: actions/upload-artifact@v4
      with:
        name: performance-benchmarks
        path: |
          reports/benchmarks/
          memory_usage.png
          *.prof
        retention-days: 30

  # Deployment and Release (Only on main branch)
  deploy:
    needs: [integration-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“‚ Checkout Repository
      uses: actions/checkout@v4
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: ðŸ”§ Install Build Dependencies
      run: |
        python -m pip install --upgrade pip build twine
    
    - name: ðŸ“¦ Build Package
      run: |
        python -m build
    
    - name: ðŸ·ï¸ Create Release Tag
      id: tag
      run: |
        VERSION=$(python setup.py --version)
        echo "version=$VERSION" >> $GITHUB_OUTPUT
        git tag -a "v$VERSION" -m "Release version $VERSION"
    
    - name: ðŸ“‹ Generate Release Notes
      run: |
        python scripts/generate_reports.py --type=release --version=${{ steps.tag.outputs.version }}
    
    - name: ðŸ“¤ Upload Release Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: release-artifacts-${{ steps.tag.outputs.version }}
        path: |
          dist/
          RELEASE_NOTES.md
        retention-days: 90
